name: Performance Tests

on:
  schedule:
    # Run every Sunday at 2 AM UTC
    - cron: '0 2 * * 0'
  workflow_dispatch:  # Allow manual triggering

permissions:
  contents: read
  actions: write  # For uploading artifacts

# Cancel redundant workflow runs to save compute resources
concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  performance-tests:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@e468171a9de216ec08956ac3ada2f0791b6bd435 # v3

      - name: Start services
        run: docker-compose up -d

      - name: Wait for services
        run: |
          echo "Waiting for services to be ready via API Gateway..."
          sleep 30

          # Verify services are healthy via API Gateway (port 80)
          curl -f http://localhost/api/weight/health || exit 1
          curl -f http://localhost/api/billing/health || exit 1
          curl -f http://localhost/api/shift/health || exit 1

      - name: Set up Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 # v5
        with:
          python-version: '3.11'

      - name: Install performance testing tools
        run: |
          pip install locust pytest-benchmark httpx

      - name: Create performance test script
        run: |
          cat > performance_test.py << 'EOF'
          import httpx
          import time
          import statistics
          from concurrent.futures import ThreadPoolExecutor, as_completed

          # All services accessed via API Gateway on port 80
          BASE_URL_WEIGHT = "http://localhost/api/weight"
          BASE_URL_BILLING = "http://localhost/api/billing"
          BASE_URL_SHIFT = "http://localhost/api/shift"

          def test_weight_service_throughput():
              """Test weight service can handle concurrent requests"""
              print("\n=== Weight Service Throughput Test ===")

              def make_request(i):
                  start = time.time()
                  response = httpx.get(f"{BASE_URL_WEIGHT}/health")
                  duration = time.time() - start
                  return response.status_code == 200, duration

              num_requests = 100
              max_workers = 10

              with ThreadPoolExecutor(max_workers=max_workers) as executor:
                  futures = [executor.submit(make_request, i) for i in range(num_requests)]
                  results = [f.result() for f in as_completed(futures)]

              success_count = sum(1 for success, _ in results if success)
              durations = [duration for _, duration in results]

              print(f"Total requests: {num_requests}")
              print(f"Successful: {success_count}")
              print(f"Failed: {num_requests - success_count}")
              print(f"Average response time: {statistics.mean(durations):.3f}s")
              print(f"Median response time: {statistics.median(durations):.3f}s")
              print(f"95th percentile: {statistics.quantiles(durations, n=20)[18]:.3f}s")

              assert success_count >= num_requests * 0.95, "Success rate below 95%"
              assert statistics.mean(durations) < 1.0, "Average response time too high"

          def test_billing_service_throughput():
              """Test billing service can handle concurrent requests"""
              print("\n=== Billing Service Throughput Test ===")

              def make_request(i):
                  start = time.time()
                  response = httpx.get(f"{BASE_URL_BILLING}/health")
                  duration = time.time() - start
                  return response.status_code == 200, duration

              num_requests = 100
              max_workers = 10

              with ThreadPoolExecutor(max_workers=max_workers) as executor:
                  futures = [executor.submit(make_request, i) for i in range(num_requests)]
                  results = [f.result() for f in as_completed(futures)]

              success_count = sum(1 for success, _ in results if success)
              durations = [duration for _, duration in results]

              print(f"Total requests: {num_requests}")
              print(f"Successful: {success_count}")
              print(f"Failed: {num_requests - success_count}")
              print(f"Average response time: {statistics.mean(durations):.3f}s")
              print(f"Median response time: {statistics.median(durations):.3f}s")

              assert success_count >= num_requests * 0.95, "Success rate below 95%"

          def test_shift_service_throughput():
              """Test shift service can handle concurrent requests"""
              print("\n=== Shift Service Throughput Test ===")

              def make_request(i):
                  start = time.time()
                  response = httpx.get(f"{BASE_URL_SHIFT}/health")
                  duration = time.time() - start
                  return response.status_code == 200, duration

              num_requests = 100
              max_workers = 10

              with ThreadPoolExecutor(max_workers=max_workers) as executor:
                  futures = [executor.submit(make_request, i) for i in range(num_requests)]
                  results = [f.result() for f in as_completed(futures)]

              success_count = sum(1 for success, _ in results if success)
              durations = [duration for _, duration in results]

              print(f"Total requests: {num_requests}")
              print(f"Successful: {success_count}")
              print(f"Failed: {num_requests - success_count}")
              print(f"Average response time: {statistics.mean(durations):.3f}s")

              assert success_count >= num_requests * 0.95, "Success rate below 95%"

          if __name__ == "__main__":
              test_weight_service_throughput()
              test_billing_service_throughput()
              test_shift_service_throughput()
              print("\n=== All Performance Tests Passed ===")
          EOF

      - name: Run performance tests
        run: python performance_test.py

      - name: Generate performance report
        run: |
          cat > performance-report.md << 'EOF'
          # Performance Test Report

          **Date:** $(date)
          **Commit:** ${{ github.sha }}

          ## Test Results

          Performance tests completed successfully.

          ### Metrics
          - All services maintained >95% success rate
          - Response times within acceptable limits
          - Concurrent request handling verified

          ### Services Tested
          - Weight Service (port 5001)
          - Billing Service (port 5002)
          - Shift Service (port 5003)

          EOF

      - name: Upload performance report
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: performance-report
          path: performance-report.md

      - name: Show service metrics
        run: |
          echo "=== Prometheus Metrics via API Gateway ==="
          curl -s http://localhost/api/weight/metrics | grep -E "http_requests_total|http_request_duration"
          curl -s http://localhost/api/billing/metrics | grep -E "http_requests_total|http_request_duration"
          curl -s http://localhost/api/shift/metrics | grep -E "http_requests_total|http_request_duration"

      - name: Stop services
        if: always()
        run: docker-compose down -v
